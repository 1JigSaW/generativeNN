{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\n",
    "# from keras.layers.merge import _Merge\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class GAN():\n",
    "    def __init__(self\n",
    "        , input_dim\n",
    "        , discriminator_conv_filters\n",
    "        , discriminator_conv_kernel_size\n",
    "        , discriminator_conv_strides\n",
    "        , discriminator_batch_norm_momentum\n",
    "        , discriminator_activation\n",
    "        , discriminator_dropout_rate\n",
    "        , discriminator_learning_rate\n",
    "        , generator_initial_dense_layer_size\n",
    "        , generator_upsample\n",
    "        , generator_conv_filters\n",
    "        , generator_conv_kernel_size\n",
    "        , generator_conv_strides\n",
    "        , generator_batch_norm_momentum\n",
    "        , generator_activation\n",
    "        , generator_dropout_rate\n",
    "        , generator_learning_rate\n",
    "        , optimiser\n",
    "        , z_dim\n",
    "        ):\n",
    "\n",
    "        self.name = 'gan'\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.discriminator_conv_filters = discriminator_conv_filters\n",
    "        self.discriminator_conv_kernel_size = discriminator_conv_kernel_size\n",
    "        self.discriminator_conv_strides = discriminator_conv_strides\n",
    "        self.discriminator_batch_norm_momentum = discriminator_batch_norm_momentum\n",
    "        self.discriminator_activation = discriminator_activation\n",
    "        self.discriminator_dropout_rate = discriminator_dropout_rate\n",
    "        self.discriminator_learning_rate = discriminator_learning_rate\n",
    "\n",
    "        self.generator_initial_dense_layer_size = generator_initial_dense_layer_size\n",
    "        self.generator_upsample = generator_upsample\n",
    "        self.generator_conv_filters = generator_conv_filters\n",
    "        self.generator_conv_kernel_size = generator_conv_kernel_size\n",
    "        self.generator_conv_strides = generator_conv_strides\n",
    "        self.generator_batch_norm_momentum = generator_batch_norm_momentum\n",
    "        self.generator_activation = generator_activation\n",
    "        self.generator_dropout_rate = generator_dropout_rate\n",
    "        self.generator_learning_rate = generator_learning_rate\n",
    "        \n",
    "        self.optimiser = optimiser\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.n_layers_discriminator = len(discriminator_conv_filters)\n",
    "        self.n_layers_generator = len(generator_conv_filters)\n",
    "\n",
    "        self.weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "        self.d_losses = []\n",
    "        self.g_losses = []\n",
    "\n",
    "        self.epoch = 0\n",
    "\n",
    "        self._build_discriminator()\n",
    "        self._build_generator()\n",
    "\n",
    "        self._build_adversarial()\n",
    "\n",
    "    def get_activation(self, activation):\n",
    "        if activation == 'leaky_relu':\n",
    "            layer = LeakyReLU(alpha = 0.2)\n",
    "        else:\n",
    "            layer = Activation(activation)\n",
    "        return layer\n",
    "\n",
    "    def _build_discriminator(self):\n",
    "\n",
    "        ### THE discriminator\n",
    "        discriminator_input = Input(shape=self.input_dim, name='discriminator_input')\n",
    "\n",
    "        x = discriminator_input\n",
    "\n",
    "        for i in range(self.n_layers_discriminator):\n",
    "\n",
    "            x = Conv2D(\n",
    "                filters = self.discriminator_conv_filters[i]\n",
    "                , kernel_size = self.discriminator_conv_kernel_size[i]\n",
    "                , strides = self.discriminator_conv_strides[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'discriminator_conv_' + str(i)\n",
    "                , kernel_initializer = self.weight_init\n",
    "                )(x)\n",
    "\n",
    "            if self.discriminator_batch_norm_momentum and i > 0:\n",
    "                x = BatchNormalization(momentum = self.discriminator_batch_norm_momentum)(x)\n",
    "\n",
    "            x = self.get_activation(self.discriminator_activation)(x)\n",
    "\n",
    "            if self.discriminator_dropout_rate:\n",
    "                x = Dropout(rate = self.discriminator_dropout_rate)(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        discriminator_output = Dense(1, activation='sigmoid', kernel_initializer = self.weight_init)(x)\n",
    "\n",
    "        self.discriminator = Model(discriminator_input, discriminator_output)\n",
    "\n",
    "\n",
    "    def _build_generator(self):\n",
    "\n",
    "        ### THE generator\n",
    "\n",
    "        generator_input = Input(shape=(self.z_dim,), name='generator_input')\n",
    "\n",
    "        x = generator_input\n",
    "\n",
    "        x = Dense(np.prod(self.generator_initial_dense_layer_size), kernel_initializer = self.weight_init)(x)\n",
    "\n",
    "        if self.generator_batch_norm_momentum:\n",
    "            x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)\n",
    "\n",
    "        x = self.get_activation(self.generator_activation)(x)\n",
    "\n",
    "        x = Reshape(self.generator_initial_dense_layer_size)(x)\n",
    "\n",
    "        if self.generator_dropout_rate:\n",
    "            x = Dropout(rate = self.generator_dropout_rate)(x)\n",
    "\n",
    "        for i in range(self.n_layers_generator):\n",
    "\n",
    "            if self.generator_upsample[i] == 2:\n",
    "                x = UpSampling2D()(x)\n",
    "                x = Conv2D(\n",
    "                    filters = self.generator_conv_filters[i]\n",
    "                    , kernel_size = self.generator_conv_kernel_size[i]\n",
    "                    , padding = 'same'\n",
    "                    , name = 'generator_conv_' + str(i)\n",
    "                    , kernel_initializer = self.weight_init\n",
    "                )(x)\n",
    "            else:\n",
    "\n",
    "                x = Conv2DTranspose(\n",
    "                    filters = self.generator_conv_filters[i]\n",
    "                    , kernel_size = self.generator_conv_kernel_size[i]\n",
    "                    , padding = 'same'\n",
    "                    , strides = self.generator_conv_strides[i]\n",
    "                    , name = 'generator_conv_' + str(i)\n",
    "                    , kernel_initializer = self.weight_init\n",
    "                    )(x)\n",
    "\n",
    "            if i < self.n_layers_generator - 1:\n",
    "\n",
    "                if self.generator_batch_norm_momentum:\n",
    "                    x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)\n",
    "\n",
    "                x = self.get_activation(self.generator_activation)(x)\n",
    "                    \n",
    "                \n",
    "            else:\n",
    "\n",
    "                x = Activation('tanh')(x)\n",
    "\n",
    "\n",
    "        generator_output = x\n",
    "\n",
    "        self.generator = Model(generator_input, generator_output)\n",
    "\n",
    "       \n",
    "    def get_opti(self, lr):\n",
    "        if self.optimiser == 'adam':\n",
    "            opti = Adam(lr=lr, beta_1=0.5)\n",
    "        elif self.optimiser == 'rmsprop':\n",
    "            opti = RMSprop(lr=lr)\n",
    "        else:\n",
    "            opti = Adam(lr=lr)\n",
    "\n",
    "        return opti\n",
    "\n",
    "    def set_trainable(self, m, val):\n",
    "        m.trainable = val\n",
    "        for l in m.layers:\n",
    "            l.trainable = val\n",
    "\n",
    "\n",
    "    def _build_adversarial(self):\n",
    "        \n",
    "        ### COMPILE DISCRIMINATOR\n",
    "\n",
    "        self.discriminator.compile(\n",
    "        optimizer=self.get_opti(self.discriminator_learning_rate)  \n",
    "        , loss = 'binary_crossentropy'\n",
    "        ,  metrics = ['accuracy']\n",
    "        )\n",
    "        \n",
    "        ### COMPILE THE FULL GAN\n",
    "\n",
    "        self.set_trainable(self.discriminator, False)\n",
    "\n",
    "        model_input = Input(shape=(self.z_dim,), name='model_input')\n",
    "        model_output = self.discriminator(self.generator(model_input))\n",
    "        self.model = Model(model_input, model_output)\n",
    "\n",
    "        self.model.compile(optimizer=self.get_opti(self.generator_learning_rate) , loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        self.set_trainable(self.discriminator, True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def train_discriminator(self, x_train, batch_size, using_generator):\n",
    "\n",
    "        valid = np.ones((batch_size,1))\n",
    "        fake = np.zeros((batch_size,1))\n",
    "\n",
    "        if using_generator:\n",
    "            true_imgs = next(x_train)[0]\n",
    "            if true_imgs.shape[0] != batch_size:\n",
    "                true_imgs = next(x_train)[0]\n",
    "        else:\n",
    "            idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "            true_imgs = x_train[idx]\n",
    "        \n",
    "        noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        d_loss_real, d_acc_real =   self.discriminator.train_on_batch(true_imgs, valid)\n",
    "        d_loss_fake, d_acc_fake =   self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss =  0.5 * (d_loss_real + d_loss_fake)\n",
    "        d_acc = 0.5 * (d_acc_real + d_acc_fake)\n",
    "\n",
    "        return [d_loss, d_loss_real, d_loss_fake, d_acc, d_acc_real, d_acc_fake]\n",
    "\n",
    "    def train_generator(self, batch_size):\n",
    "        valid = np.ones((batch_size,1))\n",
    "        noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
    "        return self.model.train_on_batch(noise, valid)\n",
    "\n",
    "\n",
    "    def train(self, x_train, batch_size, epochs, run_folder\n",
    "    , print_every_n_batches = 50\n",
    "    , using_generator = False):\n",
    "\n",
    "        for epoch in range(self.epoch, self.epoch + epochs):\n",
    "\n",
    "            d = self.train_discriminator(x_train, batch_size, using_generator)\n",
    "            g = self.train_generator(batch_size)\n",
    "\n",
    "            print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f] [G acc: %.3f]\" % (epoch, d[0], d[1], d[2], d[3], d[4], d[5], g[0], g[1]))\n",
    "\n",
    "            self.d_losses.append(d)\n",
    "            self.g_losses.append(g)\n",
    "\n",
    "            if epoch % print_every_n_batches == 0:\n",
    "                self.sample_images(run_folder)\n",
    "                self.model.save_weights(os.path.join(run_folder, 'weights/weights-%d.h5' % (epoch)))\n",
    "                self.model.save_weights(os.path.join(run_folder, 'weights/weights.h5'))\n",
    "                self.save_model(run_folder)\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "    \n",
    "    def sample_images(self, run_folder):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.z_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        gen_imgs = 0.5 * (gen_imgs + 1)\n",
    "        gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "\n",
    "        fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "        cnt = 0\n",
    "\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]), cmap = 'gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(os.path.join(run_folder, \"images/sample_%d.png\" % self.epoch))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def plot_model(self, run_folder):\n",
    "        plot_model(self.model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes = True, show_layer_names = True)\n",
    "        plot_model(self.discriminator, to_file=os.path.join(run_folder ,'viz/discriminator.png'), show_shapes = True, show_layer_names = True)\n",
    "        plot_model(self.generator, to_file=os.path.join(run_folder ,'viz/generator.png'), show_shapes = True, show_layer_names = True)\n",
    "\n",
    "\n",
    "\n",
    "    def save(self, folder):\n",
    "\n",
    "        with open(os.path.join(folder, 'params.pkl'), 'wb') as f:\n",
    "            pkl.dump([\n",
    "                self.input_dim\n",
    "                , self.discriminator_conv_filters\n",
    "                , self.discriminator_conv_kernel_size\n",
    "                , self.discriminator_conv_strides\n",
    "                , self.discriminator_batch_norm_momentum\n",
    "                , self.discriminator_activation\n",
    "                , self.discriminator_dropout_rate\n",
    "                , self.discriminator_learning_rate\n",
    "                , self.generator_initial_dense_layer_size\n",
    "                , self.generator_upsample\n",
    "                , self.generator_conv_filters\n",
    "                , self.generator_conv_kernel_size\n",
    "                , self.generator_conv_strides\n",
    "                , self.generator_batch_norm_momentum\n",
    "                , self.generator_activation\n",
    "                , self.generator_dropout_rate\n",
    "                , self.generator_learning_rate\n",
    "                , self.optimiser\n",
    "                , self.z_dim\n",
    "                ], f)\n",
    "\n",
    "        self.plot_model(folder)\n",
    "\n",
    "    def save_model(self, run_folder):\n",
    "        self.model.save(os.path.join(run_folder, 'model.h5'))\n",
    "        self.discriminator.save(os.path.join(run_folder, 'discriminator.h5'))\n",
    "        self.generator.save(os.path.join(run_folder, 'generator.h5'))\n",
    "        pkl.dump(self, open( os.path.join(run_folder, \"obj.pkl\"), \"wb\" ))\n",
    "\n",
    "    def load_weights(self, filepath):\n",
    "        self.model.load_weights(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
